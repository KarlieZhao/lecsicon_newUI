"use client"
import { useRef, useEffect, useState } from 'react'
import banner from '../../public/banner.png'
import { useWindowHeight } from './components/resize'
import './globals.css'
import GeneratorSection from './components/generator'
import WordDisplay from './components/wordDisplay'
import Image from 'next/image'

export default function Home() {
  const bannerRef = useRef<HTMLImageElement>(null);
  const collectionRef = useRef<HTMLDivElement>(null);
  const [bannerHeight, setBannerHeight] = useState(500);
  const windowHeight = useWindowHeight();
  const [maxHeight, setMaxHeight] = useState(windowHeight - bannerHeight - 25);
  const [logoHover, setLogoHover] = useState(false);
  const [readMore, setReadMore] = useState("Read More");

  useEffect(() => {
    if (bannerRef.current)
      setBannerHeight(bannerRef.current.getBoundingClientRect().height);
    if (collectionRef.current) {
      const calculatedMaxHeight = windowHeight - bannerHeight - 25;
      setMaxHeight(calculatedMaxHeight);
      // console.log(calculatedMaxHeight)
      collectionRef.current.style.height = `${calculatedMaxHeight}px`
    }
  }, [bannerHeight, windowHeight])

  const openReadMore = () => {
    setReadMore("Back")
    // Shift the page down
    window.scrollTo({
      top: window.innerHeight - 30,
      behavior: 'smooth',
    });
  }
  const closeReadMore = () => {
    setReadMore("Read More")
    // Shift the page down
    window.scrollTo({
      top: 0,
      behavior: 'smooth',
    });
  }
  const openPromptnCode = () => {

  }

  return (
    <>
      <div className='background'>
        <div
          onMouseOver={() => { setLogoHover(true) }}
          onMouseOut={() => { setLogoHover(false) }} >
          <Image src={banner} ref={bannerRef} className={`banner ${logoHover ? "blur" : null}`} alt="" />
          <div className={`acrostic ${logoHover ? "visible" : "invisible"}`}>
            <span className='text-highlight'>An acrostic is a poem or other word composition in which the first letter of each new line spells out a word, message or the alphabet.
            </span> </div>
        </div>

        <div className='top-box'><span style={{ cursor: "pointer" }}>Lecsicon by ¡wénrán zhào!</span></div>
        <div className='bottom-box'>
          <div style={{ marginLeft: "3rem" }}>Lecsicon is a growing collection of over 24,000 acrostic lines. </div>
          <div className='read-more'
            onClick={() => { return readMore === "Back" ? closeReadMore() : openReadMore() }}>{readMore}</div>
        </div>
        <div className='left-box'></div>
        <div className='right-box' onClick={() => { openPromptnCode() }}><div>Prompt & Code</div></div>
      </div >

      <div className='collection' ref={collectionRef}>
        <h1>From the Collection</h1>
        <WordDisplay maxHeight={maxHeight} />
      </div>
      <GeneratorSection />

      {/* read more  */}
      <section className='about'>
        Lecsicon is a collection of over 24,000 acrostics generated by OpenAI&apos;s language model
        GPT, which serve as a conduit between machine comprehension and human interpretation.
        <br /><br />Following a specific prompt, GPT
        made a sentence with a series of words whose first letters
        sequentially spelled out the given word. At a large scale, this
        process gives rise to intriguing behavioral patterns in the
        model. The resulting acrostics also elicit gripping reflections
        on the nature of this literary device and its role in meaning
        making.

        <br /> <br />In Lecsicon, the resulting sentences offer a broader context for the original words. Many of the sentences perform similarly to Chomsky’s “colorless green ideas sleep furiously,” but others, such as “Music: Many unexpected sounds indicate creativity” and “Date: Dinner and theater experience,” seem to flesh out how the units of meaning (letter, word, sentence, paragraph) feed into each other and meaning bleeds through the edges–the fractal character of the English language.
        Large Language model capture words based on their interrelations through computation processes, like a ghost hunting through a latent vector space. In such a space, words only exist in their associations with other words, sentences emerging from context.        <br /> <br />
        {/* Upon visiting the Lecsicon web page, users can see the word-sentence pairs typed out letter-by-letter by a web-based program. Starting with a random word, the program searches the Lecsicon database for a word that has the smallest Levenshtein distance from the preceding one. Adjusting the temperature slider results in a stronger or weaker spelling similarities between the consecutive words displayed. Typing speed is also influenced by temperature-in the same way as molecular motion is.
        <br /><br /> */}
        <p>¡wénrán zhào!<br /><a href="https://theunthoughts.com/" target='_blank'>theunthoughts.com</a></p><p><small>Last Update: Jan 2025</small></p>
      </section>
    </>
  )
}
